{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "from functools import reduce\n",
    "import math as m\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gen_images(locs, features, n_gridpoints, normalize=True,\n",
    "               std_mult=0.1, n_components=2):\n",
    "    \"\"\"\n",
    "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
    "    :param locs: An array with shape [n_electrodes, 2] containing X, Y\n",
    "                        coordinates for each electrode.\n",
    "    :param features: Feature matrix as [n_samples, n_features]\n",
    "                                Features are as columns.\n",
    "                                Features corresponding to each frequency band are concatenated.\n",
    "                                (alpha1, alpha2, ..., beta1, beta2,...)\n",
    "    :param n_gridpoints: Number of pixels in the output images\n",
    "    :param normalize:   Flag for whether to normalize each band over all samples\n",
    "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
    "                        images.\n",
    "    \"\"\"\n",
    "    feat_array_temp = []\n",
    "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
    "\n",
    "    # Test whether the feature vector length is divisible by number of electrodes\n",
    "    assert features.shape[1] % nElectrodes == 0\n",
    "    n_colors = features.shape[1] // nElectrodes\n",
    "    for c in range(n_colors):\n",
    "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])\n",
    "\n",
    "    n_samples = features.shape[0]\n",
    "\n",
    "    # Interpolate the values\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
    "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
    "                     ]\n",
    "    temp_interp = []\n",
    "    for c in range(n_colors):\n",
    "        temp_interp.append(np.zeros([n_samples, n_gridpoints, n_gridpoints]))\n",
    "\n",
    "    # Interpolating\n",
    "    for i in range(n_samples):\n",
    "        for c in range(n_colors):\n",
    "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
    "                                               method='cubic', fill_value=np.nan)\n",
    "\n",
    "    for c in range(n_colors):\n",
    "        if normalize:\n",
    "            temp_interp[c][~np.isnan(temp_interp[c])] = \\\n",
    "                scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
    "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
    "    return np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]\n",
    "\n",
    "\n",
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "\n",
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,7)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (13,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta\n",
    "\n",
    "def make_frames(df,frame_duration):\n",
    "    \n",
    "    #in: dataframe or array with all channels, frame duration in seconds\n",
    "    #out: array of theta, alpha, beta averages for each probe for each time step\n",
    "    #shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    \n",
    "    Fs = 128.0\n",
    "    frame_length = Fs*frame_duration\n",
    "    frames = []\n",
    "    frames_ar_alpha= []\n",
    "    frames_ar_theta= []\n",
    "    frames_ar_beta= []\n",
    "    steps = np.arange(0,len(df),frame_length)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        ar_alpha= []\n",
    "        ar_theta= []\n",
    "        ar_beta= []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.iloc[steps[i-1]:steps[i]-1,int(channel)])\n",
    "                #print(i, channel)\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta = theta_alpha_beta_averages(f,Y)\n",
    "                #print theta, alpha, beta\n",
    "                #ar_alpha.append([alpha])\n",
    "                #ar_theta.append([theta])\n",
    "                #ar_beta.append([beta])\n",
    "                frame.append([theta])\n",
    "            \n",
    "        frames.append(frame)\n",
    "        '''        \n",
    "        print(\"________________Frame_no {\"+str(i)+\"}________________\")\n",
    "        plt.figure(figsize=(50, 6))\n",
    "        plt.plot(ar_theta,color='green',label='theta')\n",
    "        plt.plot(ar_alpha,color='blue',label='alpha')\n",
    "        plt.plot(ar_beta,color='red', label='beta' )\n",
    "        plt.legend()\n",
    "        #plt.xlabel('sampled time',fontsize=35)\n",
    "        #plt.ylabel('Hz',fontsize=35)\n",
    "        #plt.title('EEG channel '+str(d[i]), fontsize=35)\n",
    "        plt.xlabel('Sensors')\n",
    "        plt.ylabel('AVG (freq)');\n",
    "        plt.show()\n",
    "        '''\n",
    "    #print(len(frames))\n",
    "    \n",
    "    return np.array(frames)\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4\n",
    "val=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_2d = [(-2.0,4.0), #af3\n",
    "                   (2.0,4.0), #af4\n",
    "                   (-1.0,3.0),#f3\n",
    "                   (1.0,3.0),#f4\n",
    "                   (-3.0,3.0),#f7\n",
    "                   (3.0,3.0),#f8\n",
    "                   (-2.0,2.0),#fc5\n",
    "                   (2.0,2.0),#fc6\n",
    "                   (-2.0,-2.0),#p7\n",
    "                   (2.0,-2.0),#p8\n",
    "                   (-4.0,1.0),#t7\n",
    "                   (4.0,1.0),#t8\n",
    "                   (-1.0,-3.0),#o1\n",
    "                   (1.0,-3.0)] #o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub1\n",
      "trail0\n",
      "trail1\n",
      "trail2\n",
      "trail3\n",
      "trail4\n",
      "trail5\n",
      "trail6\n",
      "trail7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-96ec8da5d9b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         '''\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/vikmachine/Desktop/research/subjects_data/subject'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_trial'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "ar_all=[]\n",
    "\n",
    "#create 40 csv files for each subject\n",
    "\n",
    "for sub_name in range(1,33):\n",
    "    print('sub'+str(sub_name))\n",
    "    for trial in range(0,40):\n",
    "        print(\"trail\"+str(trial))\n",
    "        dat=[]\n",
    "        if sub_name<10:\n",
    "            fname = \"/home/vikmachine/Desktop/research/MAIN/mainprog/data/s0\"+str(sub_name)+\".dat\"\n",
    "        else:\n",
    "            fname = \"/home/vikmachine/Desktop/research/MAIN/mainprog/data/s\"+str(sub_name)+\".dat\"\n",
    "        f = open(fname, 'rb')                 #Read the file in Binary mode\n",
    "        x = pickle.load(f, encoding='latin1')\n",
    "        data=x['data']\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[0].append(data[trial][1][j]) #0\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[1].append(data[trial][17][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[2].append(data[trial][2][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[3].append(data[trial][19][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[4].append(data[trial][3][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[5].append(data[trial][20][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[6].append(data[trial][4][j]) \n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[7].append(data[trial][21][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[8].append(data[trial][11][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[9].append(data[trial][29][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[10].append(data[trial][7][j])\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[11].append(data[trial][25][j])#13\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[12].append(data[trial][13][j]) #25\n",
    "        dat.append([])\n",
    "        for j in range(0, 8064):\n",
    "            dat[13].append(data[trial][31][j])\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        d=['Fp1','AF3','F3','F7','FC5','FC1','C3','T7','CP5','CP1','P3','P7','PO3','O1','Oz','Pz','Fp2','AF4','Fz','F4','F8','FC6','FC2','Cz','C4','T8','CP6','CP2','P4','P8','PO4','O2','hEOG (horizontal EOG, hEOG1 - hEOG2)','vEOG (vertical EOG, vEOG1 - vEOG2)','zEMG (Zygomaticus Major EMG, zEMG1 - zEMG2)','tEMG (Trapezius EMG, tEMG1 - tEMG2)','GSR (values from Twente converted to Geneva format (Ohm))','Respiration belt','Plethysmograph','Temperature']\n",
    "        sns.set()\n",
    "        for i in range(0, 32):\n",
    "            plt.figure(figsize=(50, 6))\n",
    "            plt.plot(dat[i])\n",
    "            plt.xlabel('sampled time',fontsize=35)\n",
    "            plt.ylabel('Hz',fontsize=35)\n",
    "            plt.title('EEG channel '+str(d[i]), fontsize=35)\n",
    "            plt.show()\n",
    "        '''\n",
    "\n",
    "        df = pd.DataFrame(dat)\n",
    "        df=df.T\n",
    "        df.to_csv('/home/vikmachine/Desktop/research/subjects_data/subject'+str(sub_name)+'_trial'+str(trial)+'.csv')\n",
    "        #df. info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
    "    '''\n",
    "    IN: \n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    \n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = Fs * frame_duration\n",
    "    \n",
    "    print('Generating training data...')\n",
    "    \n",
    "    \n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        \n",
    "        data=pd.read_csv(file)\n",
    "        data=data.drop(['Unnamed: 0'], axis=1)\n",
    "        df = pd.DataFrame(data)\n",
    "        #print(df)\n",
    "        \n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),14*3)\n",
    "        \n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3) \n",
    "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        print(labels[0])\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "        \n",
    "    print(X)\n",
    "    return X,np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub1\n",
      "sub2\n",
      "sub3\n",
      "sub4\n",
      "sub5\n",
      "sub6\n",
      "sub7\n",
      "sub8\n",
      "sub9\n",
      "sub10\n",
      "sub11\n",
      "sub12\n",
      "sub13\n",
      "sub14\n",
      "sub15\n",
      "sub16\n",
      "sub17\n",
      "sub18\n",
      "sub19\n",
      "sub20\n",
      "sub21\n",
      "sub22\n",
      "sub23\n",
      "sub24\n",
      "sub25\n",
      "sub26\n",
      "sub27\n",
      "sub28\n",
      "sub29\n",
      "sub30\n",
      "sub31\n",
      "sub32\n",
      "Generating training data...\n",
      "Processing session:  /home/vikmachine/Desktop/research/subjects_data/subject1_trial0.csv . ( 1  of  1280 )\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on <class 'pandas.core.indexes.range.RangeIndex'> with these indexers [0.0] of <class 'numpy.float64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0a43e52e2cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mframe_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-8dd1a45e0b82>\u001b[0m in \u001b[0;36mmake_data_pipeline\u001b[0;34m(file_names, labels, image_size, frame_duration, overlap)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mX_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#steps = np.arange(0,len(df),frame_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mX_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-ce3ad3a17996>\u001b[0m in \u001b[0;36mmake_frames\u001b[0;34m(df, frame_duration)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0msnippet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0;31m#print(i, channel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mget_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnippet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1419\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m                 \u001b[0;31m# This is an elided recursive call to iloc/loc/etc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not applicable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_slice_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;31m# if we are accessing via lowered dim, use the last dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   2911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m             return slice(\n\u001b[0;32m-> 2913\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"slice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2914\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"slice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"slice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_indexer\u001b[0;34m(self, form, key, kind)\u001b[0m\n\u001b[1;32m   4748\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4749\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4750\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4751\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[0;34m(self, form, key)\u001b[0m\n\u001b[1;32m   3075\u001b[0m         \"\"\"\n\u001b[1;32m   3076\u001b[0m         raise TypeError(\n\u001b[0;32m-> 3077\u001b[0;31m             \u001b[0;34mf\"cannot do {form} indexing on {type(self)} with these \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m             \u001b[0;34mf\"indexers [{key}] of {type(key)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot do slice indexing on <class 'pandas.core.indexes.range.RangeIndex'> with these indexers [0.0] of <class 'numpy.float64'>"
     ]
    }
   ],
   "source": [
    "file_names=[]\n",
    "for sub_name in range(1,33):\n",
    "    print('sub'+str(sub_name))\n",
    "    for trial in range(0,40):\n",
    "        file_names.append('/home/vikmachine/Desktop/research/subjects_data/subject'+str(sub_name)+'_trial'+str(trial)+'.csv')\n",
    "len(file_names)\n",
    "\n",
    "label=[]\n",
    "labels=[]\n",
    "with open('/home/vikmachine/Desktop/research/MAIN/mainprog/data/label_class_0.dat') as scores:\n",
    "    for line in scores:\n",
    "        splitted_line = line.split(' ')\n",
    "        for values in splitted_line:\n",
    "            value_as_int = int(values)\n",
    "            labels.append(value_as_int)\n",
    "\n",
    "    \n",
    "image_size = 28\n",
    "frame_duration = 2.0\n",
    "overlap = 0.5\n",
    "X, y = make_data_pipeline(file_names, labels, image_size, frame_duration, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39680, 28, 28, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39680,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y=y.reshape(1280*31)\n",
    "#y=y.reshape(15360)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f48d2a36748>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plt.imshow(X[71433])\n",
    "plt.imshow((X[3955]* 255).astype(np.uint8))\n",
    "#print(X[798])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (27776, 28, 28, 3)\n",
      "27776 train samples\n",
      "11904 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30,shuffle=True)\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, ConvLSTM2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess=tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 200\n",
    "\n",
    "dense_layers = [2]\n",
    "layer_sizes = [32,128]\n",
    "conv_layers = [3]\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(valence)3-conv-32-nodes-2-dense-1588375655\n",
      "WARNING:tensorflow:From /home/vikmachine/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vikmachine/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 23,586\n",
      "Trainable params: 23,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/vikmachine/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 27776 samples, validate on 11904 samples\n",
      "Epoch 1/200\n",
      "27648/27776 [============================>.] - ETA: 0s - loss: 0.5538 - accuracy: 0.8182"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bb7ec04a0fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                       shuffle=True,callbacks=[tensorboard])\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                                          verbose=0)\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"(valence){}-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
    "            print(NAME)\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(32, (3, 3), padding='same',input_shape=(28,28,3)))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            for i in range(conv_layer-1):\n",
    "                model.add(Conv2D(32, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for i in range(dense_layer-1):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "                \n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(num_classes))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            # initiate RMSprop optimizer\n",
    "            opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "            # Let's train the model using RMSprop\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.summary()\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_test, y_test),\n",
    "                      shuffle=True,callbacks=[tensorboard])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 31, 28, 28, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from keras.models import load_modelX=X.reshape(1280,31,28,28,3)\n",
    "X=X.reshape(1280,31,28,28,3)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=[]\n",
    "labels=[]\n",
    "with open(\"/home/vikmachine/Desktop/research/MAIN/mainprog/data/label_class_0.dat\") as scores:\n",
    "    for line in scores:\n",
    "        splitted_line = line.split(' ')\n",
    "        for values in splitted_line:\n",
    "            value_as_int = int(values)\n",
    "            labels.append(value_as_int)\n",
    "\n",
    "Y=np.asarray(labels)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1024, 31, 28, 28, 3)\n",
      "1024 train samples\n",
      "256 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20,shuffle=True)\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, ConvLSTM2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 1\n",
    "\n",
    "nb_filters=32\n",
    "kernel_size=(3,3)\n",
    "pool_size=(2,2)\n",
    "nb_classes=2\n",
    "batch_size=62\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess=tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_7 (TimeDist (None, 31, 28, 28, 128)   3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 31, 28, 28, 128)   512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 31, 28, 28, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 31, 14, 14, 128)   0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 31, 14, 14, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 31, 14, 14, 16)    18448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 31, 14, 14, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 31, 14, 14, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 31, 7, 7, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 31, 7, 7, 16)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 31, 784)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 31, 128)           100480    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 31, 32)            20608     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 31, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 146,866\n",
      "Trainable params: 146,578\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "Train on 1024 samples, validate on 256 samples\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 63s 61ms/step - loss: 0.4939 - accuracy: 0.8008 - val_loss: 0.5901 - val_accuracy: 0.8242\n"
     ]
    }
   ],
   "source": [
    "    import datetime\n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation, Flatten, ConvLSTM2D\n",
    "    from keras.layers import Conv2D, MaxPooling2D, TimeDistributed, Reshape, LSTM, GRU, BatchNormalization\n",
    "    from keras.models import Model\n",
    "    from keras.optimizers import SGD\n",
    "    batch_size = 5\n",
    "    num_classes = 2\n",
    "    epochs = 1\n",
    "\n",
    "    nb_filters=32\n",
    "    kernel_size=(3,3)\n",
    "    pool_size=(2,2)\n",
    "    nb_classes=2\n",
    "    batch_size=62\n",
    "    \n",
    "    #values below were changed according to test cases\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    # first layer\n",
    "    model.add(TimeDistributed(Conv2D(128,(3,3), padding='same', data_format=\"channels_last\"), \n",
    "                              input_shape=(31,28,28,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # hidden layer\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(16,(3,3), padding='same', data_format=\"channels_last\") \n",
    "                              ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # hidden layer\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(128)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    # output layer\n",
    "    # Change size of layer follow experiment design\n",
    "    model.add(LSTM(32, recurrent_dropout=0.3 ,return_sequences=True, implementation=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(16, recurrent_dropout=0.3,return_sequences=False, implementation=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-7)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics= ['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=False)\n",
    "    \n",
    "model.save('Valency_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
